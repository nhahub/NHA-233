# ğŸ‹ï¸â€â™‚ï¸ Coachy â€“ AI Gym Coach

## 1ï¸âƒ£ Introduction

**Coachy** is an AI-powered virtual gym coach designed to put a **complete gym experience inside every home**.

The concept is simple:
You open the camera â€” from your laptop, phone, or any device â€” perform your exercise, and **Coachy gives you instant live feedback** about your form:

* *â€œLower your hips.â€*
* *â€œExtend your arms fully.â€*
* *â€œKeep your elbows tucked.â€*

Coachy currently supports **four core exercises**:
**Squats, Push-ups, Biceps Curls, and Lateral Raises.**

Our goal is to give everyone a **smart, accessible, and real-time** coaching tool without needing any equipment or special setup.

### `Website`

You can access the live system here:

Website: [https://coachyfit.web.app/trainee/dashboard]

---

## 2ï¸âƒ£ Data Collection

To train Coachyâ€™s models, we needed high-quality videos of people performing each exercise **correctly and consistently**.

Our data collection process had two main parts:

### **1. Manual Web Scraping**

* We visited multiple training and workout websites
* Downloaded videos where the exercise form was **clean and correct**
* Manually filtered all samples to keep only high-quality movements
* Removed bad form, occlusions, incorrect angles, and noisy videos

### **2. Recording Our Own Videos (Very Important Step)**

To make sure the model sees the **same distribution of camera angles, lighting, distances, and real-world noise** that it will face on the website, we also:

* Recorded videos using **our own mobile phones**
* Asked our friends to perform the exercises and contributed many samples
* Ensured that the videos matched the typical conditions users will have (home, normal lighting, normal camera distance)

This step was **crucial**, because it helped the model generalize to real users â€” not just professional studio footage.
`Special thanks to all our friends who helped us build a more robust and realistic dataset â¤ï¸`.

---

---


## 3ï¸âƒ£ Feature Engineering

### 3.1 Extracting Pose Landmarks

Each video was fed into **MediaPipe Pose**, which outputs the full set of **33 landmarks** (x, y, visibility) per frame.

For each exercise:

1. We extracted all frames
2. Stored the 33 landmarks in a CSV per video
3. Merged all CSVs into one dataset per exercise
4. Selected only the landmarks relevant to the movement (not all 33 are needed)

---

## 3.2 Landmark Selection per Exercise

Different exercises activate different joints.
Below is the exact table of landmarks used for each exercise.
(All include: **x, y, visibility**)

---

### ğŸŸ¦ **Squats**

| Side      | Landmarks Used                                                                   |
| --------- | -------------------------------------------------------------------------------- |
| **LEFT**  | LEFT_SHOULDER, LEFT_HIP, LEFT_KNEE, LEFT_ANKLE, LEFT_FOOT_INDEX, LEFT_HEEL       |
| **RIGHT** | RIGHT_SHOULDER, RIGHT_HIP, RIGHT_KNEE, RIGHT_ANKLE, RIGHT_FOOT_INDEX, RIGHT_HEEL |

---

### ğŸŸ¥ **Biceps Curls**

| Side      | Landmarks Used                                                                             |
| --------- | ------------------------------------------------------------------------------------------ |
| **LEFT**  | LEFT_SHOULDER, LEFT_ELBOW, LEFT_WRIST, LEFT_PINKY, LEFT_INDEX, LEFT_THUMB, LEFT_HIP        |
| **RIGHT** | RIGHT_SHOULDER, RIGHT_ELBOW, RIGHT_WRIST, RIGHT_PINKY, RIGHT_INDEX, RIGHT_THUMB, RIGHT_HIP |

---

### ğŸŸ© **Push-ups**

| Side      | Landmarks Used                                                                                                                              |
| --------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| **LEFT**  | LEFT_SHOULDER, LEFT_ELBOW, LEFT_WRIST, LEFT_PINKY, LEFT_INDEX, LEFT_THUMB, LEFT_HIP, LEFT_KNEE, LEFT_ANKLE, LEFT_FOOT, LEFT_HEEL            |
| **RIGHT** | RIGHT_SHOULDER, RIGHT_ELBOW, RIGHT_WRIST, RIGHT_PINKY, RIGHT_INDEX, RIGHT_THUMB, RIGHT_HIP, RIGHT_KNEE, RIGHT_ANKLE, RIGHT_FOOT, RIGHT_HEEL |

---

### ğŸŸ¨ **Lateral Raises**

| Both Sides                                                                                                                                                                      |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_ELBOW, RIGHT_ELBOW, LEFT_WRIST, RIGHT_WRIST, LEFT_PINKY, RIGHT_PINKY, LEFT_INDEX, RIGHT_INDEX, LEFT_THUMB, RIGHT_THUMB, LEFT_HIP, RIGHT_HIP |

---

## 3.3 Angle & Distance Features (Major Improvement)

After the first attempt using raw landmarks only, we added **biomechanical angle features** (and some distances).
This dramatically improved all models.

### â­ Lateral Raises â€“ Angle Features

```
left_shoulder_angle  
right_shoulder_angle  
left_elbow_angle  
right_elbow_angle  
left_torso_angle  
right_torso_angle  
left_shoulder_elevation  
right_shoulder_elevation  
left_wrist_angle  
right_wrist_angle  
left_arm_drift  
right_arm_drift  
```

---

### â­ Push-ups â€“ Angle Features

```
active_arm  
elbow_flexion_angle  
shoulder_angle  
hip_angle  
torso_angle  
wrist_angle  
shoulder_elev  
torso_hip_drift  
```

---

### â­ Biceps Curls â€“ Angle Features

```
active_arm  
elbow_flexion_angle  
forearm_vertical_angle  
wrist_angle  
upper_arm_torso_angle  
torso_lean_angle  
```

---

### â­ Squats â€“ Angle Features

```
active_arm  
knee_angles  
hip_angles  
torso_angles  
ankle_angles  
```

---

## 3.4 One-Side Active Arm Selection

Finally, we improved performance by using **only one side of the body** instead of both.

* If the **left** side has higher visibility â†’ use **all left landmarks**
* If the **right** side is clearer â†’ use **all right landmarks**

This removes the noise of the side that is partially hidden from the camera.

This upgrade made the model more stable, more accurate, and reduced unnecessary variance.

---

# ğŸ“Š **Dataset Summary per Exercise**

Below are the datasets used to train each exercise-specific model in Coachy.

---

## ğŸŸ¦ **Push-Ups Dataset**

| Item                 | Description                                                                                             |
| -------------------- | ------------------------------------------------------------------------------------------------------- |
| **Source**           | Web-scraped videos + mobile-recorded videos from friends                                                |
| **Total Videos**     | *56*                                                                                                    |
| **Frames Extracted** | *21800*                                                                                                 |
| **Landmarks Used**   | Shoulder, Elbow, Wrist, Pinky, Index, Thumb, Hip, Knee, Ankle, Foot, Heel (Left or Right only)          |
| **Angle Features**   | Elbow flexion, shoulder angle, hip angle, torso angle, wrist angle, shoulder elevation, torso-hip drift |
| **Window Size**      | 30 frames                                                                                               |
| **Stride**           | 5                                                                                                       |
| **Labels**           | Unsupervised (only good form)                                                                           |
| **Purpose**          | Anomaly detection for bad push-up form                                                                  |

---

## ğŸŸ¥ **Squats Dataset**

| Item                 | Description                                                       |
| -------------------- | ----------------------------------------------------------------- |
| **Source**           | Web-scraped videos + mobile-recorded videos from friends          |
| **Total Videos**     | *94*                                                              |
| **Frames Extracted** | *42400*                                                           |
| **Landmarks Used**   | Shoulder, Hip, Knee, Ankle, Foot Index, Heel (Left or Right only) |
| **Angle Features**   | Knee angles, hip angles, torso angles, ankle angles               |
| **Window Size**      | 30 frames                                                         |
| **Stride**           | 5                                                                 |
| **Labels**           | Unsupervised (only good form)                                     |
| **Purpose**          | Detect shallow squats, poor depth, back arching                   |

---

## ğŸŸ© **Biceps Curls Dataset**

| Item                 | Description                                                                                 |
| -------------------- | ------------------------------------------------------------------------------------------- |
| **Source**           | Web-scraped videos + mobile-recorded videos from friends                                    |
| **Total Videos**     | *65*                                                                                        |
| **Frames Extracted** | *38400*                                                                                     |
| **Landmarks Used**   | Shoulder, Elbow, Wrist, Pinky, Index, Thumb, Hip (Left or Right only)                       |
| **Angle Features**   | Elbow flexion, forearm vertical angle, wrist angle, upper-arm torso angle, torso lean angle |
| **Window Size**      | 30 frames                                                                                   |
| **Stride**           | 5                                                                                           |
| **Labels**           | Unsupervised                                                                                |
| **Purpose**          | Detect partial ROM, swinging, weak contraction                                              |

---

## ğŸŸ¨ **Lateral Raises Dataset**

| Item                 | Description                                                           |
| -------------------- | --------------------------------------------------------------------- |
| **Source**           | Web-scraped videos + mobile-recorded videos from friends              |
| **Total Videos**     | *67*                                                                  |
| **Frames Extracted** | *28200*                                                               |
| **Landmarks Used**   | Shoulder, Elbow, Wrist, Pinky, Index, Thumb, Hip (both sides needed)  |
| **Angle Features**   | Shoulder elevation, elbow angle, wrist angle, torso angles, arm drift |
| **Window Size**      | 30 frames                                                             |
| **Stride**           | 5                                                                     |
| **Labels**           | Unsupervised                                                          |
| **Purpose**          | Detect wrist mistakes, ROM issues, elbow drop                         |

---
---

## 4ï¸âƒ£ Model Architecture

To evaluate exercise form, Coachy uses a **Transformer Autoencoder**, trained **only on correct-form videos**.
This allows the system to learn the *normal pattern* of each exercise and detect deviations as **anomalies**, which correspond to bad form.

### â­ Why an Autoencoder?

All videos we collected (from websites + our mobile phones) contain **good form only**.
So instead of training a classifier (which needs good vs bad), we train an **autoencoder** that learns:

* how correct movements look
* how correct joints move together
* how correct angles change over time

When the user performs the exercise:

* If the movement is correct â†’ the model reconstructs it well â†’ **low error**
* If the movement is wrong â†’ reconstruction fails â†’ **high error = bad form alert**

This approach is perfect for **anomaly detection on motion sequences**.

---

## 4.1 Input Representation

### âœ”ï¸ Features

Each frame contains:

* Selected pose landmarks (x, y, visibility)
* Exercise-specific angle features (like shoulder angle, elbow flexion, torso lean, etc.)
* One-side â€œactive armâ€ selection to reduce noise

### âœ”ï¸ Scaling

All numerical features are standardized using:

```python
StandardScaler()
```

This stabilizes training and prevents landmarks with large value ranges from dominating the loss.

### âœ”ï¸ Temporal Windows

Instead of feeding individual frames, we feed **windows of 30 frames** with a **stride of 5**, giving the model a full short motion sequence.

This allows the Transformer to learn the **motion pattern**, not just static posture.

---

## 4.2 Transformer Autoencoder Architecture

Your model architecture:

```
Input (num_features)
      â†“  Linear (input projection)
Encoder â†’ TransformerEncoder (6 layers, 8 heads)
      â†“  
Decoder â†’ TransformerDecoder (6 layers, 8 heads)
      â†“
Output (reconstructed features)
```

### ğŸ”§ Key Components

| Component             | Description                                                           |
| --------------------- | --------------------------------------------------------------------- |
| **Input Projection**  | Maps raw features â†’ 128-dimensional embedding                         |
| **Encoder**           | Learns the correct motion pattern of the exercise                     |
| **Decoder**           | Attempts to reconstruct the original sequence from the encoded memory |
| **Output Projection** | Converts model output back to original feature size                   |

### ğŸ“ Model Hyperparameters

* `d_model = 128`
* `nhead = 8`
* `num_layers = 6` for encoder + decoder
* `optimizer = Adam(lr=1e-4)`
* `loss = MSELoss()`
* `batch_size = 32`
* `epochs = 30`

---

## 4.3 Loss Function

We use **Mean Squared Error (MSE)** between the input sequence and the reconstructed sequence:

```python
criterion = nn.MSELoss()
```

**Reason:**
If the user performs the exercise correctly, the model easily reconstructs the movement â†’ low MSE.
If the user performs it incorrectly (bad angles, wrong depth, leaning, etc.), the reconstruction is poor â†’ high MSE.

This is the core idea behind **anomaly detection**.

---

## 4.4 Why Transformers? (Technical Reasons)

Transformers outperform RNN/LSTM models for motion and time-series for several reasons:

### âœ”ï¸ 1. They capture long-range dependencies

Movement in an exercise is not only about the current frame â€” it's about **how joints move across time**.
Self-attention lets the model compare any frame to any other frame directly.

### âœ”ï¸ 2. They handle variable speed

Different people move faster or slower.
Transformers are robust to timing variation.

### âœ”ï¸ 3. They are great for multi-joint coordination

Exercise form depends on the relationship between:

* hips
* shoulders
* elbows
* wrists
* knees

Self-attention naturally models these multi-joint interactions.

### âœ”ï¸ 4. They are powerful for reconstruction tasks

The encoder learns the "ideal" movement pattern.
The decoder replicates it.
Any deviation â†’ immediate anomaly.

---

## 4.5 Summary

The Transformer Autoencoder architecture allows Coachy to:

* Learn the **correct** motion for each exercise
* Detect **incorrect** or dangerous form
* Provide **instant feedback** during the live session
* Generalize to different users, speeds, and camera setups
* Stay lightweight enough for real-time inference

---


# 5ï¸âƒ£ Real-Time Feedback Logic

Coachy provides live feedback by combining **two complementary systems**:

### **1. Rule-Based Biomechanics Feedback (Per-Frame)**

We analyzed the most common form mistakes in biomechanics (ROM errors, elbow position, depth, wrist alignmentâ€¦ etc.) and converted them into **real-time rules**.

These rules run **every frame**, so feedback like:

* â€œGo down more!â€
* â€œExtend your arms!â€
* â€œKeep your back straight!â€

â€¦is returned **instantly** the moment the mistake happens.

### **2. Transformer Autoencoder (Anomaly Detection)**

If none of the explicit rules fire, we let the Transformer check the frame window.
If reconstruction error is high â†’ the model detects **bad form** automatically.

This gives us a hybrid system:

| Component       | Detects                                   |
| --------------- | ----------------------------------------- |
| **Rule-based**  | Specific biomechanical mistakes           |
| **Autoencoder** | Any unfamiliar / unusual movement pattern |

Together, this guarantees we catch **all bad forms**, even the ones we didnâ€™t write explicit rules for.

---

# 5.1 Push-Ups â€“ Real-Time Feedback Rules

For push-ups, the key feature is:

```
elbow_flexion_angle = angles[1]
```

The movement is divided into 4 phases based on elbow angle:

| Phase  | Condition                 | Meaning              |
| ------ | ------------------------- | -------------------- |
| **P1** | angle â‰¥ 150Â°              | Top / full extension |
| **P2** | angle decreasing (150â†’65) | Going down           |
| **P3** | angle â‰¤ 65Â°               | Bottom position      |
| **P4** | angle increasing (65â†’150) | Going up             |

### **ROM Rules (Range of Motion)**

Coachy checks:

#### **1. Incomplete Bottom Range**

If user starts going down but doesnâ€™t reach the bottom â†’
â†’ **â€œGo Down More!â€**

#### **2. Incomplete Top Range**

If user comes up but doesnâ€™t reach full extension â†’
â†’ **â€œGo Up More!â€**

### **3. Anomaly Detection**

If reconstruction error > threshold â†’
â†’ **â€œPOOR FORM!â€**

### **4. Rep Counting**

A valid rep is:

```
P4 â†’ P1    (Going up â†’ Fully extended)
```

Invalid reps do not increase the counter.

---

# 5.2 Squats â€“ Real-Time Feedback Rules

Key feature:

```
knee_angle = angles[1]
```

Phases:

| Phase  | Condition        |            |
| ------ | ---------------- | ---------- |
| **S1** | angle > 160Â°     | Standing   |
| **S2** | angle decreasing | Going down |
| **S3** | angle â‰¤ 90Â°      | Bottom     |
| **S4** | angle increasing | Going up   |

### **ROM Rules**

#### **1. Not Going Deep Enough**

If user starts descending but never reaches proper bottom â†’
â†’ **â€œNot Going Low Enough!â€**

#### **2. Back Arching**

If torso angle exceeds threshold during descent â†’
â†’ **â€œDonâ€™t Arch Your Back!â€**

### **3. Anomaly Detection**

If reconstruction error > threshold:
â†’ **â€œBad Form!â€**

### **4. Rep Counting**

Valid rep happens on:

```
S4 â†’ S1    (Going up â†’ Standing fully)
```

---

# 5.3 Biceps Curls â€“ Real-Time Feedback Rules

Key angle:

```
elbow_flexion_angle = angles[1]
```

Phases:

| Phase  | Condition        |                       |
| ------ | ---------------- | --------------------- |
| **B1** | angle â‰¥ 160Â°     | Rest / Full extension |
| **B2** | angle decreasing | Going up              |
| **B3** | angle â‰¤ 60Â°      | Top contraction       |
| **B4** | angle increasing | Going down            |

### **ROM Rules**

#### **1. Not Fully Extending Arms (bottom ROM)**

â†’ **â€œExtend your arms more!â€**

#### **2. Weak contraction at top**

â†’ **â€œContract your arms more!â€**

### **3. Autoencoder Detection**

If reconstruction error high:
â†’ **â€œPOOR FORM!â€**

### **4. Rep Counting**

Valid rep:

```
B4 â†’ B1
```

---

# 5.4 Lateral Raises â€“ Real-Time Feedback Rules

Key angle:

```
shoulder_angle = (angles[0] + angles[1]) / 2
```

Phases:

| Phase   | Condition        |            |
| ------- | ---------------- | ---------- |
| **LR1** | angle â‰¤ 30Â°      | Rest       |
| **LR2** | angle increasing | Going up   |
| **LR3** | angle â‰¥ 75Â°      | Top        |
| **LR4** | angle decreasing | Going down |

### **ROM Rules**

#### **1. Not Lowering Enough**

â†’ **â€œRelax arms at the end!â€**

#### **2. Not Raising Enough**

â†’ **â€œRaise Elbow!â€**

#### **3. Wrist Higher than Elbow**

Biomechanically dangerous for shoulder â†’
â†’ **â€œWrist higher than elbow!â€**

### **4. Autoencoder Detection**

â†’ **â€œPOOR FORM!â€**

### **5. Rep Counting**

Valid rep:

```
LR4 â†’ LR1
```

---

# 5.5 Summary of Feedback System

| Component                 | Role                                  |
| ------------------------- | ------------------------------------- |
| **Angle-based phases**    | Identify motion stage (up/down/rest)  |
| **ROM rules**             | Ensure correct depth and extension    |
| **Joint alignment rules** | Wristâ€“elbow, back arching, etc.       |
| **Autoencoder error**     | Detects any unusual / unseen movement |
| **Rep counter**           | Tracks valid reps only                |

The result is a **fast, precise, hybrid feedback system** that works frame-by-frame while also analyzing short movement sequences.

---







